---
layout: page
title: Multi-Armed Bandits Bandits
description: Final Project for Advanced Algorithms
img:
importance: 3
category: fun
related_publications: False
---

[Notes](/assets/pdf/bandit_algos_notes.pdf) on measure theoretic probability and bandits.

The goal of my final proect was to present the regret bound on the well known thompson sampling algorithm. Although it worked well in practice, rigorous guarantees on it's regret were unknown. Goyal and Agarwal provided a bound in 2012. My report reproduces their work and can be found [here](/assets/pdf/advanced_algorithms_final_project.pdf)